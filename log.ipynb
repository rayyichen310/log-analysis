{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_parser.py\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_general_logs(logfile, start_year=2005):\n",
    "    \"\"\"\n",
    "    解析一般日誌文件並返回 DataFrame。\n",
    "\n",
    "    Parameters:\n",
    "        logfile (str): 日誌文件路徑。\n",
    "        start_year (int): 日誌的起始年份。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 包含解析後日誌數據的 DataFrame。\n",
    "    \"\"\"\n",
    "    # 定義日誌行的正則匹配模式\n",
    "    # 假設每行類似: \"Aug  4 04:03:35 combo su(pam_unix)[31009]: session opened for user cyrus by (uid=0)\"\n",
    "    pattern = re.compile(r'^([A-Z][a-z]{2}\\s+\\d+\\s+\\d{2}:\\d{2}:\\d{2})\\s+(\\S+)\\s+([^:]+):\\s*(.*)$')\n",
    "    \n",
    "    # 初始化當前年份和年份是否已經增加的標記\n",
    "    current_year = start_year\n",
    "    year_incremented = False\n",
    "    \n",
    "    # 存儲解析後的日誌數據\n",
    "    rows = []\n",
    "    \n",
    "    with open(logfile, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # 跳過空行\n",
    "\n",
    "            # 嘗試匹配整體結構\n",
    "            m = pattern.match(line)\n",
    "            if m:\n",
    "                datetime_str = m.group(1)    # e.g. \"Aug  4 04:03:35\"\n",
    "                hostname = m.group(2)        # e.g. \"combo\"\n",
    "                program = m.group(3).strip() # e.g. \"sshd(pam_unix)[31672]\"\n",
    "                message = m.group(4).strip() # e.g. \"check pass; user unknown\"\n",
    "\n",
    "                # 提取月份字串以判斷年份\n",
    "                month_str = datetime_str[:3]\n",
    "\n",
    "                # 判斷是否需要切換年份（假設日誌按月份遞增，當遇到一月份時，年份增加）\n",
    "                if not year_incremented and month_str == 'Jan':\n",
    "                    current_year += 1\n",
    "                    year_incremented = True\n",
    "                elif month_str != 'Jan':\n",
    "                    year_incremented = False\n",
    "\n",
    "                # 解析日期時間，加入年份\n",
    "                try:\n",
    "                    log_datetime = datetime.strptime(f\"{datetime_str} {current_year}\", \"%b %d %H:%M:%S %Y\")\n",
    "                except ValueError as ve:\n",
    "                    print(f\"日期解析錯誤: {ve}，行內容: {line}\")\n",
    "                    continue  # 跳過解析失敗的行\n",
    "\n",
    "                # 清理程序名稱，移除 [pid] 和括號內的內容\n",
    "                program_clean = re.sub(r'\\[.*?\\]', '', program)             # 移除 [數字]\n",
    "                program_clean = re.sub(r'\\(.*?\\)', '', program_clean)      # 移除括號內內容\n",
    "                program_clean = program_clean.strip()                      # 去除前後空格\n",
    "\n",
    "                # 增加到行列表中，包含 message 和計數為1\n",
    "                rows.append((log_datetime, hostname, program_clean, message, 1))\n",
    "            else:\n",
    "                print(f\"無法解析的行: {line}\")\n",
    "\n",
    "    # 創建 DataFrame，包含 'message' 列\n",
    "    df = pd.DataFrame(rows, columns=[\"datetime\", \"hostname\", \"program\", \"message\", \"count\"])\n",
    "\n",
    "    # 確保 'datetime' 列為 datetime 類型\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def parse_ssh_logs(logfile, start_year=2005, access_token='YOUR_IPINFO_ACCESS_TOKEN'):\n",
    "    \"\"\"\n",
    "    解析 SSH 日誌文件，獲取地理位置信息，並返回 DataFrame。\n",
    "\n",
    "    Parameters:\n",
    "        logfile (str): SSH 日誌文件路徑。\n",
    "        start_year (int): 日誌的起始年份。\n",
    "        access_token (str): ipinfo 的訪問令牌，用於地理位置查詢。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 包含解析後 SSH 日誌數據的 DataFrame。\n",
    "    \"\"\"\n",
    "    import ipinfo  # 確保已安裝 ipinfo 庫：pip install ipinfo\n",
    "\n",
    "    # 定義 SSH 日誌行的正則匹配模式\n",
    "    # 假設每行類似: \"Aug  4 07:00:29 combo sshd(pam_unix)[31672]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=arx58.internetdsl.tpnet.pl\"\n",
    "    log_pattern = re.compile(\n",
    "        r'^(?P<datetime>[A-Z][a-z]{2}\\s+\\d+\\s+\\d{2}:\\d{2}:\\d{2})\\s+'  # 日期時間\n",
    "        r'(?P<hostname>\\S+)\\s+'                                   # 主機名\n",
    "        r'(?P<program>sshd\\(pam_unix\\)\\[\\d+\\]):\\s+'              # 程式名稱和 PID\n",
    "        r'authentication failure;.*'                              # 認證失敗標識\n",
    "        r'rhost=(?P<rhost>[^\\s]+)'                                # rhost（IP 或域名）\n",
    "        r'(?:\\s+user=(?P<user>\\S+))?'                            # 可選的 user=欄位\n",
    "    )\n",
    "\n",
    "    # 初始化數據列表\n",
    "    logs = []\n",
    "\n",
    "    # 初始化年份\n",
    "    current_year = start_year\n",
    "    year_incremented = False  # 標記是否已經增加年份\n",
    "\n",
    "    # 設置 ipinfo 的 access token\n",
    "    handler = ipinfo.getHandler(access_token)\n",
    "\n",
    "    def get_country(ip):\n",
    "        \"\"\"\n",
    "        根據 IP 地址獲取國家名稱。\n",
    "        如果 rhost 是域名或無法解析，返回 'Unknown'。\n",
    "        \"\"\"\n",
    "        # 檢查是否為有效的 IP 地址\n",
    "        ip_pattern = re.compile(r'^(?:\\d{1,3}\\.){3}\\d{1,3}$')\n",
    "        if not ip_pattern.match(ip):\n",
    "            return 'Unknown'\n",
    "        try:\n",
    "            details = handler.getDetails(ip)\n",
    "            return details.country_name if details.country_name else 'Unknown'\n",
    "        except:\n",
    "            return 'Unknown'\n",
    "\n",
    "    # 讀取日誌文件並解析\n",
    "    with open(logfile, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # 跳過空行\n",
    "\n",
    "            match = log_pattern.match(line)\n",
    "            if match:\n",
    "                log_entry = match.groupdict()\n",
    "                try:\n",
    "                    # 提取月份信息\n",
    "                    month_str = log_entry['datetime'][:3]\n",
    "\n",
    "                    # 判斷是否需要切換年份\n",
    "                    if not year_incremented and month_str == 'Jan':\n",
    "                        current_year += 1\n",
    "                        year_incremented = True\n",
    "                    elif month_str != 'Jan':\n",
    "                        year_incremented = False\n",
    "\n",
    "                    # 解析日期並加入年份\n",
    "                    log_entry['datetime'] = datetime.strptime(\n",
    "                        f\"{log_entry['datetime']} {current_year}\",\n",
    "                        \"%b %d %H:%M:%S %Y\"\n",
    "                    )\n",
    "                except ValueError as ve:\n",
    "                    print(f\"日期解析錯誤: {ve}，行內容: {line}\")\n",
    "                    continue  # 跳過解析失敗的行\n",
    "\n",
    "                # 獲取國家信息\n",
    "                country = get_country(log_entry['rhost'])\n",
    "                log_entry['country'] = country\n",
    "\n",
    "                logs.append(log_entry)\n",
    "\n",
    "    # 將數據轉換為 DataFrame\n",
    "    df = pd.DataFrame(logs)\n",
    "\n",
    "    # 如果數據框為空，提示無有效數據\n",
    "    if df.empty:\n",
    "        print(\"無有效的 SSH 日誌數據可供分析。\")\n",
    "    else:\n",
    "        # 提取日期部分\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无法解析的行: Sep 28 09:08:56 combo last message repeated 2 times\n",
      "无法解析的行: Sep 28 09:09:19 combo exiting on signal 15\n",
      "无法解析的行: Oct 25 10:06:52 combo last message repeated 14 times\n",
      "无法解析的行: Oct 25 10:07:15 combo exiting on signal 15\n",
      "无法解析的行: Nov 22 07:36:50 combo last message repeated 3 times\n",
      "无法解析的行: Nov 22 09:31:42 combo last message repeated 2 times\n",
      "无法解析的行: Nov 22 14:31:49 combo last message repeated 3 times\n",
      "无法解析的行: Nov 22 14:32:21 combo last message repeated 3 times\n",
      "无法解析的行: Nov 22 17:26:15 combo last message repeated 2 times\n",
      "无法解析的行: Nov 23 08:16:52 combo last message repeated 2 times\n",
      "无法解析的行: Nov 23 13:41:37 combo last message repeated 2 times\n",
      "无法解析的行: Nov 23 14:41:27 combo last message repeated 3 times\n",
      "无法解析的行: Nov 23 14:46:09 combo last message repeated 2 times\n",
      "无法解析的行: Nov 23 21:36:40 combo last message repeated 3 times\n",
      "无法解析的行: Nov 29 04:43:12 combo last message repeated 3 times\n",
      "无法解析的行: Dec  6 12:21:26 combo exiting on signal 15\n",
      "无法解析的行: Dec  9 09:43:13 combo exiting on signal 15\n",
      "无法解析的行: Jan 26 12:20:32 combo exiting on signal 15\n",
      "\n",
      "篩選日期範圍：從 2006-02-14 到 2006-02-28\n",
      "\n",
      "各程式的出現次數：\n",
      "       program  count\n",
      "1         sshd    338\n",
      "0         ftpd    203\n",
      "3  unix_chkpwd     67\n",
      "2      telnetd      2\n",
      "\n",
      "可用的程式列表：\n",
      "1. sshd - 338 次\n",
      "2. ftpd - 203 次\n",
      "3. unix_chkpwd - 67 次\n",
      "4. telnetd - 2 次\n",
      "\n",
      "顯示程式 'telnetd' 的日誌：\n",
      "\n",
      "2006-02-25 04:02:59 combo telnetd: ttloop:  peer died: Invalid or incomplete multibyte or wide character\n",
      "2006-02-25 06:14:13 combo telnetd: ttloop:  read: Connection timed out\n"
     ]
    }
   ],
   "source": [
    "# general_log_analysis.py\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 日誌文件名稱\n",
    "    logfile = 'Linux.log'  # 修改為您的日誌文件路徑\n",
    "\n",
    "    # 解析日誌\n",
    "    df = parse_general_logs(logfile)\n",
    "\n",
    "    # 1. 讓使用者選擇要查看的天數，默認為全部日誌\n",
    "    while True:\n",
    "        try:\n",
    "            days_input = input(\"請輸入要查看的天數（留空表示查看所有日誌）：\").strip()\n",
    "            if days_input == '':\n",
    "                days_choice = None\n",
    "                break\n",
    "            else:\n",
    "                days_choice = int(days_input)\n",
    "                if days_choice > 0:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"請輸入一個正整數。\")\n",
    "        except ValueError:\n",
    "            print(\"無效輸入，請輸入數字。\")\n",
    "\n",
    "    # 2. 根據選擇的天數篩選日誌\n",
    "    if days_choice is not None:\n",
    "        latest_date = df['datetime'].max()\n",
    "        start_date = latest_date - pd.Timedelta(days=days_choice)\n",
    "        print(f\"\\n篩選日期範圍：從 {start_date.strftime('%Y-%m-%d')} 到 {latest_date.strftime('%Y-%m-%d')}\\n\")\n",
    "        filtered_df = df[(df['datetime'] >= start_date) & (df['datetime'] <= latest_date)]\n",
    "    else:\n",
    "        filtered_df = df.copy()\n",
    "\n",
    "    # 3. 彙總在所選時間範圍內每個程式的日誌出現次數\n",
    "    df_summary = filtered_df.groupby('program')['count'].sum().reset_index().sort_values(by='count', ascending=False)\n",
    "\n",
    "    # 顯示彙總結果\n",
    "    print(\"各程式的出現次數：\")\n",
    "    print(df_summary)\n",
    "\n",
    "    # 4. 列出所有唯一的程式名稱並讓使用者選擇程式\n",
    "    unique_programs = df_summary['program'].tolist()\n",
    "    print(\"\\n可用的程式列表：\")\n",
    "    for idx, prog in enumerate(unique_programs, 1):\n",
    "        print(f\"{idx}. {prog} - {df_summary.iloc[idx-1]['count']} 次\")\n",
    "\n",
    "    # 5. 讓使用者選擇要查看的程式\n",
    "    while True:\n",
    "        try:\n",
    "            prog_choice = input(f\"\\n請輸入要查看的程式編號（1-{len(unique_programs)}，留空表示退出）：\").strip()\n",
    "            if prog_choice == '':\n",
    "                print(\"退出程式。\")\n",
    "                exit()\n",
    "            prog_choice = int(prog_choice)\n",
    "            if 1 <= prog_choice <= len(unique_programs):\n",
    "                selected_program = unique_programs[prog_choice - 1]\n",
    "                break\n",
    "            else:\n",
    "                print(f\"請輸入一個介於 1 和 {len(unique_programs)} 之間的數字。\")\n",
    "        except ValueError:\n",
    "            print(\"無效輸入，請輸入數字。\")\n",
    "\n",
    "    # 6. 顯示選定程式的日誌\n",
    "    print(f\"\\n顯示程式 '{selected_program}' 的日誌：\\n\")\n",
    "    selected_logs = filtered_df[filtered_df['program'] == selected_program]\n",
    "\n",
    "    if not selected_logs.empty:\n",
    "        # 格式化顯示\n",
    "        for index, row in selected_logs.iterrows():\n",
    "            print(f\"{row['datetime'].strftime('%Y-%m-%d %H:%M:%S')} {row['hostname']} {row['program']}: {row['message']}\")\n",
    "    else:\n",
    "        print(\"沒有找到符合條件的日誌。\")\n",
    "\n",
    "    # 可選：保存篩選後的日誌到 CSV\n",
    "    save_choice = input(\"\\n是否將選定程式的日誌保存到 'selected_program_logs.csv'？（y/n）：\").strip().lower()\n",
    "    if save_choice == 'y':\n",
    "        selected_logs.to_csv('selected_program_logs.csv', index=False, encoding='utf-8')\n",
    "        print(\"選定程式的日誌已保存到 'selected_program_logs.csv'。\")\n",
    "\n",
    "    # 可選：視覺化所有程式的出現次數\n",
    "    visualize_choice = input(\"\\n是否生成所有程式出現次數的柱狀圖？（y/n）：\").strip().lower()\n",
    "    if visualize_choice == 'y':\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # 生成柱狀圖，顯示前 20 個程式\n",
    "        sns.barplot(x='count', y='program', data=df_summary.head(20), color='skyblue')  # 顯示前 20 個，使用單一顏色\n",
    "\n",
    "        # 設置英文標題和標籤\n",
    "        plt.title('Top 20 Programs by Log Count')\n",
    "        plt.xlabel('Log Count')\n",
    "        plt.ylabel('Program')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 保存圖表為圖片\n",
    "        plt.savefig('program_summary_top20.png')  # 保存圖表為圖片\n",
    "        plt.show()\n",
    "        print(\"柱狀圖已保存為 'program_summary_top20.png'。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ray03\\AppData\\Local\\Temp\\ipykernel_56592\\3864807002.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['hour'] = df_filtered['datetime'].dt.hour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 最近兩週每日登錄失敗次數 ===\n",
      "date\n",
      "2006-02-15    37\n",
      "2006-02-16    32\n",
      "2006-02-17    20\n",
      "2006-02-18    27\n",
      "2006-02-19    30\n",
      "2006-02-20    26\n",
      "2006-02-22    20\n",
      "2006-02-23    26\n",
      "2006-02-24    60\n",
      "2006-02-25     6\n",
      "2006-02-26    36\n",
      "2006-02-27     6\n",
      "2006-02-28    10\n",
      "\n",
      "=== 來源 IP 統計（前10名） ===\n",
      "                        IP Address  Attempt Count\n",
      "                     69.42.162.212             22\n",
      "                       203.95.1.26             21\n",
      "                    83.228.113.166             20\n",
      "                    206.51.234.204             20\n",
      "             66-50-123-66.prtc.net             19\n",
      " c-24-7-117-28.hsd1.ca.comcast.net             18\n",
      "                   221.230.128.214             16\n",
      "             vedgi-gw.rosprint.net             16\n",
      " xdsl-81-173-145-209.netcologne.de             15\n",
      "www.buller.hoover.fresno.k12.ca.us             10\n",
      "\n",
      "=== 使用者名稱統計（前10名） ===\n",
      "Username  Attempt Count\n",
      "    root            209\n",
      " Unknown             67\n",
      "    test             38\n",
      "  nobody             16\n",
      "     fax              6\n",
      "\n",
      "=== 攻擊時間分佈（按小時） ===\n",
      "hour\n",
      "1     10\n",
      "2     10\n",
      "3      1\n",
      "4      4\n",
      "5     21\n",
      "6      7\n",
      "7     20\n",
      "9     10\n",
      "10    10\n",
      "11    40\n",
      "12    37\n",
      "13    36\n",
      "14    31\n",
      "15    11\n",
      "16    20\n",
      "17     1\n",
      "18    19\n",
      "19     6\n",
      "20    10\n",
      "21    10\n",
      "23    22\n",
      "\n",
      "=== 來源國家統計（前10名） ===\n",
      "       Country  Attempt Count\n",
      "       Unknown            163\n",
      "         China             80\n",
      " United States             55\n",
      "      Bulgaria             20\n",
      "   Philippines             10\n",
      "        Taiwan              2\n",
      "United Kingdom              2\n",
      "   South Korea              1\n",
      "       Romania              1\n",
      "         Spain              1\n",
      "\n",
      "分析結果已保存到以下文件：\n",
      "- output-ssh\\csv\\daily_login_failures.csv\n",
      "- output-ssh\\csv\\ip_failures.csv\n",
      "- output-ssh\\csv\\user_failures.csv\n",
      "- output-ssh\\csv\\hourly_failures.csv\n",
      "- output-ssh\\csv\\country_failures.csv\n",
      "- output-ssh\\images\\daily_login_failures.png\n",
      "- output-ssh\\images\\top10_ip_failures.png\n",
      "- output-ssh\\images\\top10_user_failures.png\n",
      "- output-ssh\\images\\hourly_login_failures.png\n",
      "- output-ssh\\images\\top10_countries_failures.png\n"
     ]
    }
   ],
   "source": [
    "# ssh_log_analysis.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def main():\n",
    "    # 日誌文件名稱\n",
    "    logfile = 'Linux.log'  # 修改為您的 SSH 日誌文件路徑\n",
    "\n",
    "    # 設定 ipinfo 的 access token\n",
    "    access_token = '87957b8996885a'  # 替換為您的 ipinfo access token\n",
    "\n",
    "    # 解析 SSH 日誌\n",
    "    df = parse_ssh_logs(logfile, access_token=access_token)\n",
    "\n",
    "    # 如果 DataFrame 為空，退出\n",
    "    if df.empty:\n",
    "        print(\"無有效的 SSH 日誌數據可供分析。\")\n",
    "        return\n",
    "\n",
    "    # 提取日期部分\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "\n",
    "    # 設定分析範圍：最近兩週（14天）\n",
    "    end_date = df['date'].max()\n",
    "    start_date = end_date - timedelta(days=13)  # 包含今天，共14天\n",
    "\n",
    "    # 過濾範圍內的數據\n",
    "    df_filtered = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(\"在指定的兩週範圍內未找到有效的 SSH 登錄嘗試記錄。\")\n",
    "        return\n",
    "\n",
    "    # 1. 每日登錄失敗次數統計\n",
    "    daily_stats = df_filtered['date'].value_counts().sort_index()\n",
    "\n",
    "    # 2. 按來源 IP 統計嘗試次數\n",
    "    ip_stats = df_filtered['rhost'].value_counts().reset_index()\n",
    "    ip_stats.columns = ['IP Address', 'Attempt Count']\n",
    "\n",
    "    # 3. 按使用者名稱統計嘗試次數\n",
    "    user_stats = df_filtered['user'].fillna('Unknown').value_counts().reset_index()\n",
    "    user_stats.columns = ['Username', 'Attempt Count']\n",
    "\n",
    "    # 4. 時間分佈分析（按小時）\n",
    "    df_filtered['hour'] = df_filtered['datetime'].dt.hour\n",
    "    time_stats = df_filtered['hour'].value_counts().sort_index()\n",
    "\n",
    "    # 5. 來源國家地理位置分析\n",
    "    country_stats = df_filtered['country'].value_counts().reset_index()\n",
    "    country_stats.columns = ['Country', 'Attempt Count']\n",
    "\n",
    "    # 6. 輸出分析結果\n",
    "    print(\"=== 最近兩週每日登錄失敗次數 ===\")\n",
    "    print(daily_stats.to_string())\n",
    "\n",
    "    print(\"\\n=== 來源 IP 統計（前10名） ===\")\n",
    "    print(ip_stats.head(10).to_string(index=False))\n",
    "\n",
    "    print(\"\\n=== 使用者名稱統計（前10名） ===\")\n",
    "    print(user_stats.head(10).to_string(index=False))\n",
    "\n",
    "    print(\"\\n=== 攻擊時間分佈（按小時） ===\")\n",
    "    print(time_stats.to_string())\n",
    "\n",
    "    print(\"\\n=== 來源國家統計（前10名） ===\")\n",
    "    print(country_stats.head(10).to_string(index=False))\n",
    "\n",
    "    # 創建資料夾結構\n",
    "    output_folder = 'output-ssh'\n",
    "    csv_folder = os.path.join(output_folder, 'csv')\n",
    "    img_folder = os.path.join(output_folder, 'images')\n",
    "\n",
    "    # 確保資料夾存在\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "\n",
    "    # 7.1 每日登錄失敗次數折線圖\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x=daily_stats.index, y=daily_stats.values, marker='o')\n",
    "    plt.title('Daily SSH Login Failures in the Last Two Weeks')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Failures')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_folder, 'daily_login_failures.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # 7.2 來源 IP 前10名柱狀圖\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='IP Address', y='Attempt Count', data=ip_stats.head(10))\n",
    "    plt.title('Top 10 IP Addresses by SSH Login Failures')\n",
    "    plt.xlabel('IP Address')\n",
    "    plt.ylabel('Number of Failures')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_folder, 'top10_ip_failures.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # 7.3 使用者名稱前10名柱狀圖\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Username', y='Attempt Count', data=user_stats.head(10))\n",
    "    plt.title('Top 10 Usernames by SSH Login Failures')\n",
    "    plt.xlabel('Username')\n",
    "    plt.ylabel('Number of Failures')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_folder, 'top10_user_failures.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # 7.4 時間分佈直方圖\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=time_stats.index, y=time_stats.values, color='coral')\n",
    "    plt.title('Hourly Distribution of SSH Login Failures')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Failures')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_folder, 'hourly_login_failures.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # 7.5 來源國家前10名柱狀圖\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Country', y='Attempt Count', data=country_stats.head(10))\n",
    "    plt.title('Top 10 Countries by SSH Login Failures')\n",
    "    plt.xlabel('Country')\n",
    "    plt.ylabel('Number of Failures')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_folder, 'top10_countries_failures.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # 8. 將分析結果保存到文件\n",
    "    daily_stats.to_csv(os.path.join(csv_folder, 'daily_login_failures.csv'), index=True, header=[\"Number of Failures\"])\n",
    "    ip_stats.to_csv(os.path.join(csv_folder, 'ip_failures.csv'), index=False)\n",
    "    user_stats.to_csv(os.path.join(csv_folder, 'user_failures.csv'), index=False)\n",
    "    time_stats.to_csv(os.path.join(csv_folder, 'hourly_failures.csv'), index=True, header=[\"Number of Failures\"])\n",
    "    country_stats.to_csv(os.path.join(csv_folder, 'country_failures.csv'), index=False)\n",
    "\n",
    "    print(\"\\n分析結果已保存到以下文件：\")\n",
    "    print(f\"- {os.path.join(csv_folder, 'daily_login_failures.csv')}\")\n",
    "    print(f\"- {os.path.join(csv_folder, 'ip_failures.csv')}\")\n",
    "    print(f\"- {os.path.join(csv_folder, 'user_failures.csv')}\")\n",
    "    print(f\"- {os.path.join(csv_folder, 'hourly_failures.csv')}\")\n",
    "    print(f\"- {os.path.join(csv_folder, 'country_failures.csv')}\")\n",
    "    print(f\"- {os.path.join(img_folder, 'daily_login_failures.png')}\")\n",
    "    print(f\"- {os.path.join(img_folder, 'top10_ip_failures.png')}\")\n",
    "    print(f\"- {os.path.join(img_folder, 'top10_user_failures.png')}\")\n",
    "    print(f\"- {os.path.join(img_folder, 'hourly_login_failures.png')}\")\n",
    "    print(f\"- {os.path.join(img_folder, 'top10_countries_failures.png')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
